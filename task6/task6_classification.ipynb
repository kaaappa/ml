{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r-Mb7bnoaRLM"
   },
   "source": [
    "# Логичтическая регрессия, метод опорных векторов, one-hot кодирование"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pNyXo3CvaRLP"
   },
   "source": [
    "### О задании\n",
    "\n",
    "В этом задании вы:\n",
    "- настроите метод опорных векторов\n",
    "- изучите методы работы с категориальными переменными"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "ndj090dOaRLQ",
    "outputId": "fdef6337-1efe-4945-d445-fb17c46dcc4d"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "from joblib import Parallel, delayed\n",
    "import warnings, time\n",
    "warnings.simplefilter(action='ignore')\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.datasets import load_diabetes\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import copy\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1_wS0x7RaRLR"
   },
   "source": [
    "__Задание 1.__ Обучение логистической регрессии на реальных данных и оценка качества классификации.\n",
    "\n",
    "**(5 баллов)**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "94eHa5RgaRLS"
   },
   "source": [
    "Загрузим данные с конкурса [Kaggle Porto Seguro’s Safe Driver Prediction](https://www.kaggle.com/c/porto-seguro-safe-driver-prediction) (вам нужна только обучающая выборка). Задача состоит в определении водителей, которые в ближайший год воспользуются своей автомобильной страховкой (бинарная классификация). Но для нас важна будет не сама задача, а только её данные. При этом под нужды задания мы немного модифицируем датасет."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "id": "BJQn-94DaRLS"
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('train.csv', index_col=0)\n",
    "target = data.target.values\n",
    "data = data.drop('target', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u2Su7GNhaRLT"
   },
   "source": [
    "Пересемплируем выборку так, чтобы положительных и отрицательных объектов в выборке было одинаковое число. Разделим на обучающую и тестовую выборки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "id": "fot9A7L8aRLT"
   },
   "outputs": [],
   "source": [
    "np.random.seed(910)\n",
    "mask_plus = np.random.choice(np.where(target == 1)[0], 100000, replace=True)\n",
    "mask_zero = np.random.choice(np.where(target == 0)[0], 100000, replace=True)\n",
    "mask = np.concatenate([mask_plus, mask_zero])\n",
    "mask = np.sort(mask)\n",
    "\n",
    "data = data.iloc[mask]\n",
    "target = target[mask]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, target, test_size=0.5, random_state=73)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6GB0kVSoaRLT"
   },
   "source": [
    "Не забудьте отнормировать признаки (можно воспользоваться StandardScaler или сделать это вручную). Пока не будем обращать внимание на то, что некоторые признаки категориальные (этим мы займёмся позже)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "id": "5dDctZhDaRLU"
   },
   "outputs": [],
   "source": [
    "def normalize(data):\n",
    "    new_data = copy.deepcopy(data)\n",
    "    for c in data.columns:\n",
    "        new_data[c] = (new_data[c] - new_data[c].min()) / (new_data[c].max() - new_data[c].min())\n",
    "    return new_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mSrjeimpaRLU"
   },
   "source": [
    "Обучите логистическую регрессию с удобными для вас параметрами, примените регуляризацию. Сделайте предсказание на тестовой части выборки. Посчитайте accuracy, precision, recall и F меру"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "id": "A1tEHyNFaRLU"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.58863\n",
      "Precision: 0.5971208920443408\n",
      "Recall: 0.5477465238932395\n",
      "F1 Score: 0.5713690308732664\n",
      "Time taken: 0.7139253616333008 s\n"
     ]
    }
   ],
   "source": [
    "def get(X_train, X_test, y_train, y_test):\n",
    "    st = time.time()\n",
    "    model = LogisticRegression(max_iter=1000)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    print(f\"Accuracy:\", accuracy)\n",
    "    print(f\"Precision:\", precision)\n",
    "    print(f\"Recall:\", recall)\n",
    "    print(f\"F1 Score:\", f1)\n",
    "    en = time.time()\n",
    "    print(f\"Time taken: {en - st} s\")\n",
    "\n",
    "\n",
    "get(*train_test_split(normalize(data), target, test_size=0.5, random_state=73))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N9UQ31XFaRLU"
   },
   "source": [
    "__Выводы__ в свободной форме:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Accuracy: 0.59 - доля правильных предсказаний модели, составляет примерно 59%. Это означает, что модель правильно классифицировала около 59% объектов в тестовой выборке.\n",
    "\n",
    "    Precision: 0.60 - доля правильно предсказанных положительных классов среди всех предсказанных положительных классов, составляет примерно 60%. Это указывает на то, что из объектов, которые модель предсказала как положительные, около 60% действительно являются положительными.\n",
    "\n",
    "    Recall: 0.55 - доля правильно предсказанных положительных классов среди всех истинных положительных классов, составляет примерно 55%. Это означает, что модель обнаруживает около 55% всех действительных положительных случаев.\n",
    "\n",
    "    F1 Score: 0.57 - гармоническое среднее между точностью и полнотой составляет примерно 57%. Это важная метрика, особенно в случае дисбаланса классов, так как она учитывает как точность, так и полноту предсказаний."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lHvrjAQnaRLW"
   },
   "source": [
    "## Часть 2. Работа с категориальными переменными"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_doKeEKxaRLW"
   },
   "source": [
    "В этой части мы научимся обрабатывать категориальные переменные, так как закодировать их в виде чисел недостаточно (это задаёт некоторый порядок, которого на категориальных переменных может и не быть). Существует два основных способа обработки категориальных значений:\n",
    "- One-hot-кодирование\n",
    "- Счётчики (CTR, mean-target кодирование, ...) — каждый категориальный признак заменяется на среднее значение целевой переменной по всем объектам, имеющим одинаковое значение в этом признаке.\n",
    "\n",
    "Начнём с one-hot-кодирования. Допустим наш категориальный признак $f_j(x)$ принимает значения из множества $C=\\{c_1, \\dots, c_m\\}$. Заменим его на $m$ бинарных признаков $b_1(x), \\dots, b_m(x)$, каждый из которых является индикатором одного из возможных категориальных значений:\n",
    "$$\n",
    "b_i(x) = [f_j(x) = c_i]\n",
    "$$\n",
    "\n",
    "__Задание 1.__ Закодируйте все категориальные признаки с помощью one-hot-кодирования. Обучите логистическую регрессию и посмотрите, как изменилось качество модели (с тем, что было ранее). Измерьте время, потребовавшееся на обучение модели.\n",
    "\n",
    "__(3 балла)__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "GC4tPzPbaRLW"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ps_ind_01</th>\n",
       "      <th>ps_ind_02_cat</th>\n",
       "      <th>ps_ind_03</th>\n",
       "      <th>ps_ind_04_cat</th>\n",
       "      <th>ps_ind_05_cat</th>\n",
       "      <th>ps_ind_06_bin</th>\n",
       "      <th>ps_ind_07_bin</th>\n",
       "      <th>ps_ind_08_bin</th>\n",
       "      <th>ps_ind_09_bin</th>\n",
       "      <th>ps_ind_10_bin</th>\n",
       "      <th>...</th>\n",
       "      <th>ps_calc_11</th>\n",
       "      <th>ps_calc_12</th>\n",
       "      <th>ps_calc_13</th>\n",
       "      <th>ps_calc_14</th>\n",
       "      <th>ps_calc_15_bin</th>\n",
       "      <th>ps_calc_16_bin</th>\n",
       "      <th>ps_calc_17_bin</th>\n",
       "      <th>ps_calc_18_bin</th>\n",
       "      <th>ps_calc_19_bin</th>\n",
       "      <th>ps_calc_20_bin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.998215</td>\n",
       "      <td>1.366550</td>\n",
       "      <td>4.483870</td>\n",
       "      <td>0.429490</td>\n",
       "      <td>0.502265</td>\n",
       "      <td>0.351100</td>\n",
       "      <td>0.295375</td>\n",
       "      <td>0.175920</td>\n",
       "      <td>0.177605</td>\n",
       "      <td>0.000470</td>\n",
       "      <td>...</td>\n",
       "      <td>5.443865</td>\n",
       "      <td>1.443745</td>\n",
       "      <td>2.873590</td>\n",
       "      <td>7.544455</td>\n",
       "      <td>0.123355</td>\n",
       "      <td>0.630875</td>\n",
       "      <td>0.553405</td>\n",
       "      <td>0.287530</td>\n",
       "      <td>0.345000</td>\n",
       "      <td>0.152800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.017199</td>\n",
       "      <td>0.674421</td>\n",
       "      <td>2.739255</td>\n",
       "      <td>0.496689</td>\n",
       "      <td>1.501934</td>\n",
       "      <td>0.477315</td>\n",
       "      <td>0.456212</td>\n",
       "      <td>0.380753</td>\n",
       "      <td>0.382181</td>\n",
       "      <td>0.021674</td>\n",
       "      <td>...</td>\n",
       "      <td>2.342462</td>\n",
       "      <td>1.201163</td>\n",
       "      <td>1.692875</td>\n",
       "      <td>2.745287</td>\n",
       "      <td>0.328845</td>\n",
       "      <td>0.482569</td>\n",
       "      <td>0.497141</td>\n",
       "      <td>0.452612</td>\n",
       "      <td>0.475369</td>\n",
       "      <td>0.359796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>7.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 57 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           ps_ind_01  ps_ind_02_cat      ps_ind_03  ps_ind_04_cat  \\\n",
       "count  200000.000000  200000.000000  200000.000000  200000.000000   \n",
       "mean        1.998215       1.366550       4.483870       0.429490   \n",
       "std         2.017199       0.674421       2.739255       0.496689   \n",
       "min         0.000000      -1.000000       0.000000      -1.000000   \n",
       "25%         0.000000       1.000000       2.000000       0.000000   \n",
       "50%         1.000000       1.000000       4.000000       0.000000   \n",
       "75%         3.000000       2.000000       7.000000       1.000000   \n",
       "max         7.000000       4.000000      11.000000       1.000000   \n",
       "\n",
       "       ps_ind_05_cat  ps_ind_06_bin  ps_ind_07_bin  ps_ind_08_bin  \\\n",
       "count  200000.000000  200000.000000  200000.000000  200000.000000   \n",
       "mean        0.502265       0.351100       0.295375       0.175920   \n",
       "std         1.501934       0.477315       0.456212       0.380753   \n",
       "min        -1.000000       0.000000       0.000000       0.000000   \n",
       "25%         0.000000       0.000000       0.000000       0.000000   \n",
       "50%         0.000000       0.000000       0.000000       0.000000   \n",
       "75%         0.000000       1.000000       1.000000       0.000000   \n",
       "max         6.000000       1.000000       1.000000       1.000000   \n",
       "\n",
       "       ps_ind_09_bin  ps_ind_10_bin  ...     ps_calc_11     ps_calc_12  \\\n",
       "count  200000.000000  200000.000000  ...  200000.000000  200000.000000   \n",
       "mean        0.177605       0.000470  ...       5.443865       1.443745   \n",
       "std         0.382181       0.021674  ...       2.342462       1.201163   \n",
       "min         0.000000       0.000000  ...       0.000000       0.000000   \n",
       "25%         0.000000       0.000000  ...       4.000000       1.000000   \n",
       "50%         0.000000       0.000000  ...       5.000000       1.000000   \n",
       "75%         0.000000       0.000000  ...       7.000000       2.000000   \n",
       "max         1.000000       1.000000  ...      18.000000       8.000000   \n",
       "\n",
       "          ps_calc_13     ps_calc_14  ps_calc_15_bin  ps_calc_16_bin  \\\n",
       "count  200000.000000  200000.000000   200000.000000   200000.000000   \n",
       "mean        2.873590       7.544455        0.123355        0.630875   \n",
       "std         1.692875       2.745287        0.328845        0.482569   \n",
       "min         0.000000       0.000000        0.000000        0.000000   \n",
       "25%         2.000000       6.000000        0.000000        0.000000   \n",
       "50%         3.000000       7.000000        0.000000        1.000000   \n",
       "75%         4.000000       9.000000        0.000000        1.000000   \n",
       "max        13.000000      22.000000        1.000000        1.000000   \n",
       "\n",
       "       ps_calc_17_bin  ps_calc_18_bin  ps_calc_19_bin  ps_calc_20_bin  \n",
       "count   200000.000000   200000.000000   200000.000000   200000.000000  \n",
       "mean         0.553405        0.287530        0.345000        0.152800  \n",
       "std          0.497141        0.452612        0.475369        0.359796  \n",
       "min          0.000000        0.000000        0.000000        0.000000  \n",
       "25%          0.000000        0.000000        0.000000        0.000000  \n",
       "50%          1.000000        0.000000        0.000000        0.000000  \n",
       "75%          1.000000        1.000000        1.000000        0.000000  \n",
       "max          1.000000        1.000000        1.000000        1.000000  \n",
       "\n",
       "[8 rows x 57 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.59375\n",
      "Precision: 0.6017653279236895\n",
      "Recall: 0.5570560971711683\n",
      "F1 Score: 0.57854823483033\n",
      "Time taken: 3.7121293544769287 s\n"
     ]
    }
   ],
   "source": [
    "categorical_features = [c for c in data.columns if c.endswith('_cat')]\n",
    "\n",
    "encoder = OneHotEncoder(sparse_output=False, drop=\"first\")\n",
    "encoded_features = encoder.fit_transform(data[categorical_features])\n",
    "\n",
    "data_one_hot = data.drop(categorical_features, axis=1)\n",
    "encoded_df = pd.DataFrame(encoded_features, columns=encoder.get_feature_names_out(categorical_features))\n",
    "\n",
    "data_one_hot.reset_index(inplace=True, drop=True)\n",
    "data_one_hot = pd.concat([data_one_hot, encoded_df], axis=1)\n",
    "\n",
    "get(*train_test_split(normalize(data_one_hot), target, test_size=0.5, random_state=73))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "izITXcOWaRLW"
   },
   "source": [
    "Как можно было заметить, one-hot-кодирование может сильно увеличивать количество признаков в датасете, что сказывается на памяти, особенно, если некоторый признак имеет большое количество значений. Эту проблему решает другой способ кодирование категориальных признаков — счётчики. Основная идея в том, что нам важны не сами категории, а значения целевой переменной, которые имеют объекты этой категории. Каждый категориальный признак мы заменим средним значением целевой переменной по всем объектам этой же категории:\n",
    "$$\n",
    "g_j(x, X) = \\frac{\\sum_{i=1}^{l} [f_j(x) = f_j(x_i)][y_i = +1]}{\\sum_{i=1}^{l} [f_j(x) = f_j(x_i)]}\n",
    "$$\n",
    "\n",
    "__Задание 2.__ Закодируйте категориальные переменные с помощью счётчиков (ровно так, как описано выше без каких-либо хитростей). Обучите логистическую регрессию и посмотрите на качество модели на тестовом множестве. Сравните время обучения с предыдущим экспериментов. Заметили ли вы что-то интересное?\n",
    "\n",
    "__(2 балла)__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "vJmhJjcyaRLW"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.59277\n",
      "Precision: 0.5992302294426606\n",
      "Recall: 0.5629694741889084\n",
      "F1 Score: 0.5805341820916123\n",
      "Time taken: 15.150947570800781 s\n"
     ]
    }
   ],
   "source": [
    "X = data.copy()\n",
    "y = target.copy()\n",
    "\n",
    "for feature in categorical_features:\n",
    "    for i in np.unique(X[feature]):\n",
    "        X[feature][X[feature] == i] = np.mean(y[X[feature] == i])\n",
    "\n",
    "get(*train_test_split(X, y, test_size=0.5, random_state=73))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CZ6BybtVaRLW"
   },
   "source": [
    "__Вывод:__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    При использовании счётчиков F1 score немного лучше, чем в one-hot-encoding, но на обучение уходит немного больше времени (не чувствительно)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IUSCGlbhaRLW"
   },
   "source": [
    "Отметим, что такие признаки сами по себе являются классификаторами и, обучаясь на них, мы допускаем \"утечку\" целевой переменной в признаки. Это ведёт к переобучению, поэтому считать такие признаки необходимо таким образом, чтобы при вычислении для конкретного объекта его целевая метка не использовалась. Это можно делать следующими способами:\n",
    "- вычислять значение счётчика по всем объектам расположенным выше в датасете (например, если у нас выборка отсортирована по времени)\n",
    "- вычислять по фолдам, то есть делить выборку на некоторое количество частей и подсчитывать значение признаков по всем фолдам кроме текущего (как делается в кросс-валидации)\n",
    "- внесение некоторого шума в посчитанные признаки (необходимо соблюсти баланс между избавление от переобучения и полезностью признаков).\n",
    "\n",
    "__Задание 3.__ Реализуйте корректное вычисление счётчиков двумя из трех вышеперчисленных способов, сравните. Снова обучите логистическую регрессию, оцените качество. Сделайте выводы.\n",
    "\n",
    "__(3 балла)__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "YX9gBIEJaRLW"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.596\n",
      "Precision: 0.6026622437696691\n",
      "Recall: 0.5662058494486175\n",
      "F1 Score: 0.5838655185200445\n",
      "Time taken: 1.5287456512451172 s\n",
      "CPU times: total: 1.11 s\n",
      "Wall time: 1.9 s\n"
     ]
    }
   ],
   "source": [
    "# по объектам расположенным выше в датасете\n",
    "X = data.copy()\n",
    "y = target.copy()\n",
    "for feature in categorical_features:\n",
    "    ind = 0\n",
    "    ans = []\n",
    "    mp = {}\n",
    "    for j in X[feature].tolist():\n",
    "        mp[j] = mp.get(j, [0, 0])\n",
    "        mp[j][0] += y[ind]\n",
    "        mp[j][1] += 1\n",
    "        ans.append(mp[j][0] / mp[j][1])\n",
    "        ind += 1\n",
    "    X[feature] = pd.Series(ans, index=X[feature].index)\n",
    "%time get(*train_test_split(normalize(X), y, test_size=0.5, random_state=73))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.60577\n",
      "Precision: 0.6124352331606218\n",
      "Recall: 0.5785320441105961\n",
      "F1 Score: 0.5950010786821586\n",
      "Time taken: 1.3502376079559326 s\n",
      "CPU times: total: 1.16 s\n",
      "Wall time: 1.69 s\n"
     ]
    }
   ],
   "source": [
    "# по фолдам\n",
    "X = data.copy()\n",
    "y = target.copy()\n",
    "B = int(len(X) ** 0.5)\n",
    "for feature in categorical_features:\n",
    "    lst = X[feature].to_list()\n",
    "    cnts = [{} for j in range(len(X) // B + 2)]\n",
    "    sums = [{} for j in range(len(X) // B + 2)]\n",
    "    for i in range(len(X)):\n",
    "        if len(cnts[i // B]) == 0:\n",
    "            cnts[i // B + 1] = cnts[i // B].copy()\n",
    "            sums[i // B + 1] = sums[i // B].copy()\n",
    "        cnts[i // B + 1][lst[i]] = cnts[i // B + 1].get(lst[i], 0) + 1\n",
    "        sums[i // B + 1][lst[i]] = sums[i // B + 1].get(lst[i], 0) + y[i]\n",
    "    ind = 0\n",
    "    ans = []\n",
    "    for j in X[feature].tolist():\n",
    "        sum = sums[ind // B].get(j, 0) + sums[-1].get(j, 0) - sums[ind // B + 1].get(j, 0)\n",
    "        cnt = cnts[ind // B].get(j, 0) + cnts[-1].get(j, 0) - cnts[ind // B + 1].get(j, 0)\n",
    "        ans.append(0 if cnt == 0 else sum / cnt)\n",
    "        ind += 1\n",
    "    X[feature] = pd.Series(ans, index=X[feature].index)\n",
    "%time get(*train_test_split(normalize(X), y, test_size=0.5, random_state=73))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CIXbvzlWaRLX"
   },
   "source": [
    "__Вывод:__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Становится намного лучше. По фолдам работает на 1% лучше (по F1 score)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cbde96fnaRLV"
   },
   "source": [
    "## Часть 2. Метод опорных векторов и калибровка вероятностней"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mvqNBbT4aRLV"
   },
   "source": [
    "__Задание 1.__ Обучение и применение метода опорных векторов.\n",
    "\n",
    "__(1 балл)__\n",
    "\n",
    "Обучите метод опорных векторов (воспользуйтесь готовой реализацией LinearSVC из sklearn). Используйте уже загруженные и обработанные в предыдущей части данные."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "G4eGtEwzaRLV"
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(normalize(X), y, test_size=0.5, random_state=73)\n",
    "\n",
    "svc = LinearSVC(random_state=73)\n",
    "svc.fit(X_train, y_train)\n",
    "y_pred = svc.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "reSZTM1daRLV"
   },
   "source": [
    "На той же тестовой части посчитайте все те же метрики. Что вы можете сказать о полученных результатах?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "0jW0b67TaRLV"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.60505\n",
      "Precision: 0.6122388250047824\n",
      "Recall: 0.5754355122263065\n",
      "F1 Score: 0.5932669433488151\n"
     ]
    }
   ],
   "source": [
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "print(f\"Accuracy:\", accuracy)\n",
    "print(f\"Precision:\", precision)\n",
    "print(f\"Recall:\", recall)\n",
    "print(f\"F1 Score:\", f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ECd18zToaRLW"
   },
   "source": [
    "__Вывод:__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    F1 score у LinearSVC и предыдущей модели (были использованы одинаковые данные) примерно одинаковы. Заметного изменения не видно."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Report***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Узнала о новых способах подготовки данных к обучению модели (one-hot-encoding, счётчики). Пообучала модель классификации.\n",
    "    Лучше всего работали счетчики с заменой на среднее по фолдам. "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
